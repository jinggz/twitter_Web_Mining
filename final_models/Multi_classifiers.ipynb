{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Classification models\n",
    "\n",
    "The balanced and preprocessed dataset is taken for supervised classification. The preprocessed text is used as the features by converting it into vectors using TFIDF scores. The polarityNum is used as the lables. The dataset is split into train, validate and test set. Different classification models used are in this notebook ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>text_original</th>\n",
       "      <th>permalink</th>\n",
       "      <th>text_preprocessed</th>\n",
       "      <th>polarity</th>\n",
       "      <th>polarity_confidence</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>subjectivity_confidence</th>\n",
       "      <th>polarityNum</th>\n",
       "      <th>brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>948570515085713408</td>\n",
       "      <td>2018-01-03 16:03</td>\n",
       "      <td>It's 10 AM and my iPhone 7 battery is already ...</td>\n",
       "      <td>https://twitter.com/TheScottBeach/status/94857...</td>\n",
       "      <td>s iphone battery already minute phone call tol...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.894631</td>\n",
       "      <td>subjective</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>iphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>945970348436094977</td>\n",
       "      <td>2017-12-27 11:51</td>\n",
       "      <td>Apple launched three phones this year: the bez...</td>\n",
       "      <td>https://twitter.com/Today__Tech/status/9459703...</td>\n",
       "      <td>apple launched three phone year bezelbusting i...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.492551</td>\n",
       "      <td>subjective</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>iphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>951907048035270656</td>\n",
       "      <td>2018-01-12 21:01</td>\n",
       "      <td>Cut one phone completely OFF and my iPhone on ...</td>\n",
       "      <td>https://twitter.com/gods1blessings/status/9519...</td>\n",
       "      <td>cut one phone completely iphone dnd yeah ready...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.355765</td>\n",
       "      <td>subjective</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>iphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>972090952251670528</td>\n",
       "      <td>2018-03-09 13:45</td>\n",
       "      <td>Do you think Apple iphone x \"notch\" will be th...</td>\n",
       "      <td>https://twitter.com/puspakpatnaik/status/97209...</td>\n",
       "      <td>think apple iphone x notch trend flagship phon...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.577812</td>\n",
       "      <td>subjective</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>iphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>958395849737990144</td>\n",
       "      <td>2018-01-30 18:45</td>\n",
       "      <td>Fluffy Bling iPhone Case All Colors in Stock h...</td>\n",
       "      <td>https://twitter.com/IDMD_MIAMI/status/95839584...</td>\n",
       "      <td>fluffy bling iphone case color stock http shop...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.501405</td>\n",
       "      <td>subjective</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>iphone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id              date  \\\n",
       "0  948570515085713408  2018-01-03 16:03   \n",
       "1  945970348436094977  2017-12-27 11:51   \n",
       "2  951907048035270656  2018-01-12 21:01   \n",
       "3  972090952251670528  2018-03-09 13:45   \n",
       "4  958395849737990144  2018-01-30 18:45   \n",
       "\n",
       "                                       text_original  \\\n",
       "0  It's 10 AM and my iPhone 7 battery is already ...   \n",
       "1  Apple launched three phones this year: the bez...   \n",
       "2  Cut one phone completely OFF and my iPhone on ...   \n",
       "3  Do you think Apple iphone x \"notch\" will be th...   \n",
       "4  Fluffy Bling iPhone Case All Colors in Stock h...   \n",
       "\n",
       "                                           permalink  \\\n",
       "0  https://twitter.com/TheScottBeach/status/94857...   \n",
       "1  https://twitter.com/Today__Tech/status/9459703...   \n",
       "2  https://twitter.com/gods1blessings/status/9519...   \n",
       "3  https://twitter.com/puspakpatnaik/status/97209...   \n",
       "4  https://twitter.com/IDMD_MIAMI/status/95839584...   \n",
       "\n",
       "                                   text_preprocessed  polarity  \\\n",
       "0  s iphone battery already minute phone call tol...  negative   \n",
       "1  apple launched three phone year bezelbusting i...  positive   \n",
       "2  cut one phone completely iphone dnd yeah ready...  positive   \n",
       "3  think apple iphone x notch trend flagship phon...   neutral   \n",
       "4  fluffy bling iphone case color stock http shop...  positive   \n",
       "\n",
       "   polarity_confidence subjectivity  subjectivity_confidence  polarityNum  \\\n",
       "0             0.894631   subjective                      1.0         -1.0   \n",
       "1             0.492551   subjective                      1.0          1.0   \n",
       "2             0.355765   subjective                      1.0          1.0   \n",
       "3             0.577812   subjective                      1.0          0.0   \n",
       "4             0.501405   subjective                      1.0          1.0   \n",
       "\n",
       "    brand  \n",
       "0  iphone  \n",
       "1  iphone  \n",
       "2  iphone  \n",
       "3  iphone  \n",
       "4  iphone  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import dataset into pandas\n",
    "import pandas as pd\n",
    "tweets = pd.read_csv('iphone_final_14may.csv')\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    7209\n",
       "positive    7209\n",
       "neutral     7209\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.polarity.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter the neutral tweets \n",
    "\n",
    "For binary classification only tweets with positive and negative polarity are considered. But for multi-class classification this is not used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_PosNeg = tweets[(tweets.polarityNum != 0.0)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier , VotingClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data into train,validate,test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#80% train data, 10% validation data, 10% test data\n",
    "train, validate_test = train_test_split(tweets_PosNeg, test_size=0.2, random_state=1) #use tweets dataframe for multi class\n",
    "validate, test = train_test_split(validate_test, test_size=0.5, random_state=1)\n",
    "\n",
    "X_train = train['text_preprocessed'].values\n",
    "X_validate = validate['text_preprocessed'].values\n",
    "X_test = test['text_preprocessed'].values\n",
    "y_train = train['polarityNum']\n",
    "y_validate = validate['polarityNum']\n",
    "y_test = test['polarityNum']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert text into TFIDF vectors\n",
    "\n",
    " Build a TFIDF model for the training data and transform the test and validation data into it to get feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = TfidfVectorizer(norm='l2',min_df=0, use_idf= True, smooth_idf=True, sublinear_tf=True,\n",
    "                    analyzer='word',  ngram_range=(1, 2))\n",
    "\n",
    "train_features_model = v.fit(X_train)\n",
    "test_features = v.transform(X_test)\n",
    "validate_features =  v.transform(X_validate)\n",
    "train_features = v.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter tuning using GridSearchCV\n",
    "\n",
    " Parameter tuning is used to get the optimized hyper parameter for models to perform the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "clf = LogisticRegression()\n",
    "tuned_parameters = [{'C': [0.01,0.1,1,10,13,30], 'max_iter' : [200,500,1000] , 'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}] #clf = KNeighborsClassifier()\n",
    "#tuned_parameters = [{'n_neighbors': [3,5,7],'weights': ['distance','uniform']}] \n",
    "#clf = MultinomialNB()\n",
    "#tuned_parameters = [{'alpha': [1.0], 'binarize' : [None,0]}]\n",
    "#clf = SVC()\n",
    "#tuned_parameters=[{'C': np.logspace(-5, 0, 10), 'class_weight':[None, 'balanced']}]\n",
    "#clf = DecisionTreeClassifier()\n",
    "#tuned_parameters=[{'max_depth' :[3,5,7,8], 'random_state' : [7, 50,100], 'min_samples_leaf' : [5,7,9]}]\n",
    "#clf= RandomForestClassifier()\n",
    "#tuned_parameters=[{'n_estimators': [200,100,500], #'max_features': [3,7,10], #'min_samples_leaf': [ 1, 4,6], 'min_samples_split' : [2,10,20]\n",
    "                  #}]\n",
    "# clf= AdaBoostClassifier()\n",
    "# tuned_parameters=[{'n_estimators':[100,200,500]} ]\n",
    "# clf=BernoulliNB()\n",
    "# tuned_parameters=[{'alpha' : [1.0,0.0]}] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_cv = KFold(n_splits=5)\n",
    "\n",
    "classifier = GridSearchCV(clf, tuned_parameters, cv=inner_cv, scoring='f1_macro')\n",
    "model = classifier.fit(train_features, y_train)\n",
    "scores = classifier.best_score_\n",
    "scores_std = classifier.cv_results_['std_test_score']\n",
    "print('F1-macro of '+classifier.__class__.__name__+' is '+str(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different classifiers used for modelling\n",
    "\n",
    " Run the classification models one by one to see the performance on validation set and also use the model to predict the performance on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifiers = [ \n",
    "    LogisticRegression(C=30, solver='saga',max_iter=200),\n",
    "    #KNeighborsClassifier(7, weights= 'distance'), #set params\n",
    "    #SVC(kernel=\"linear\", C=1, probability=True),\n",
    "    #MultinomialNB(alpha=1.0, fit_prior=True, class_prior=None),\n",
    "    #BernoulliNB(alpha = 1.0),\n",
    "    #DecisionTreeClassifier()#max_depth = 7, min_samples_leaf = 5,\n",
    "        #random_state = 50),\n",
    "    #XGBClassifier(n_estimators = 500),\n",
    "    #RandomForestClassifier(n_estimators=500,max_features= 3),\n",
    "    #GradientBoostingClassifier(learning_rate = 0.5, n_estimators= 500),\n",
    "    AdaBoostClassifier(learning_rate = 0.5,n_estimators=500, random_state= 50),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LogisticRegression is 0.8723994452149791\n",
      "F1 of LogisticRegression is 0.8723748944185662\n",
      "Cross_validation_score of LogisticRegression is [0.84532062 0.84482011 0.83701777 0.84605377 0.83651344]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(module='sklearn*', action='ignore', category=DeprecationWarning)\n",
    "\n",
    "dense_features=train_features.toarray() #when text is used\n",
    "dense_test= validate_features.toarray()\n",
    "Model=[]\n",
    "\n",
    "for classifier in Classifiers:\n",
    "    try:\n",
    "        model = classifier.fit(train_features,y_train)\n",
    "        pred = model.predict(validate_features)\n",
    "    except Exception:\n",
    "        model = classifier.fit(dense_features,y_train)\n",
    "        pred = model.predict(dense_test)\n",
    "        \n",
    "    accuracy = accuracy_score(pred,y_validate)\n",
    "    f1 = f1_score(pred,y_validate, average = 'macro')\n",
    "    scores = cross_val_score(classifier, train_features, y_train, cv=5)\n",
    "    Model.append(classifier.__class__.__name__)\n",
    "    print('Accuracy of '+classifier.__class__.__name__+' is '+str(accuracy))    \n",
    "    print('F1 of '+classifier.__class__.__name__+' is '+str(f1)) \n",
    "    print('Cross_validation_score of '+classifier.__class__.__name__+' is '+str(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8668390433096316"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#F1 score on test data for each model\n",
    "pred_test = model.predict(test_features)\n",
    "f1_score(pred_test,y_test, average = 'macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble by voting\n",
    "\n",
    "The top three best performing individual models logistic regression, support vector machine and Naive bayes are used to build the ensemble by voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8483603920749276\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(module='sklearn*', action='ignore', category=DeprecationWarning)\n",
    "seed = 1\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "estimators = []\n",
    "model1 = LogisticRegression(C=10,max_iter=200)\n",
    "estimators.append(('logistic', model1))\n",
    "model2 = SVC(kernel=\"linear\", C=1, probability=True)\n",
    "estimators.append(('SVM', model1))\n",
    "model3 = MultinomialNB ()\n",
    "estimators.append(('NB', model3))\n",
    "# create the ensemble model\n",
    "ensemble = VotingClassifier(estimators)\n",
    "results = model_selection.cross_val_score(ensemble, train_features, y_train, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8661528998217174"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_model = ensemble.fit(train_features,y_train )\n",
    "pred = ensemble_model.predict(test_features)\n",
    "f1_score(pred,y_test, average = 'macro')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
