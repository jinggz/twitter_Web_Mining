{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>polarity_confidence</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>subjectivity_confidence</th>\n",
       "      <th>polarityNum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975487595282030592</td>\n",
       "      <td>s exact opposite current phone even let manual...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.908798</td>\n",
       "      <td>subjective</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>962319102806118400</td>\n",
       "      <td>samsung gifted free phone winter olympics athl...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.461419</td>\n",
       "      <td>subjective</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>926460821214961665</td>\n",
       "      <td>seriously aku nak buang samsung pay nie dari p...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.929383</td>\n",
       "      <td>objective</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                               text  \\\n",
       "0  975487595282030592  s exact opposite current phone even let manual...   \n",
       "1  962319102806118400  samsung gifted free phone winter olympics athl...   \n",
       "2  926460821214961665  seriously aku nak buang samsung pay nie dari p...   \n",
       "\n",
       "   polarity  polarity_confidence subjectivity  subjectivity_confidence  \\\n",
       "0  negative             0.908798   subjective                 1.000000   \n",
       "1  negative             0.461419   subjective                 1.000000   \n",
       "2  negative             0.929383    objective                 0.999998   \n",
       "\n",
       "   polarityNum  \n",
       "0         -1.0  \n",
       "1         -1.0  \n",
       "2         -1.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tweets_preprocessed = pd.read_csv('samsung_balanced_11098_preprocessed.csv')\n",
    "tweets_preprocessed.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, KFold, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(tweets_preprocessed, test_size=0.2, random_state=1)\n",
    "X_train = train['text'].values\n",
    "X_test = test['text'].values\n",
    "y_train = train['polarityNum']\n",
    "y_test = test['polarityNum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = TfidfVectorizer(norm='l2',min_df=0, use_idf=True, smooth_idf=True, sublinear_tf=True, stop_words='english', analyzer='word', ngram_range = (2,2))\n",
    "train_features_model = v.fit(X_train)\n",
    "test_features = v.transform(X_test)\n",
    "train_features = v.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper parameter tuning not perfect yet\n",
    "#Classifiers = [\n",
    "clf = KNeighborsClassifier()\n",
    "tuned_parameters = [{'n_neighbors': [3,5,7],'weights': ['distance','uniform']}]\n",
    "\n",
    "#clf = SVC()\n",
    "#tuned_parameters=[{'kernel': ['rbf','linear'],'C': [0.01,0.1,1, 10]}]\n",
    "    # clf = DecisionTreeClassifier()\n",
    "    # tuned_parameters=[]\n",
    "    # clf= RandomForestClassifier(n_estimators=200)\n",
    "    # tuned_parameters=[]\n",
    "    # clf= AdaBoostClassifier()\n",
    "    # tuned_parameters=[]\n",
    "    # clf=BernoulliNB()\n",
    "    # tuned_parameters=[] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E.g \"LabelKFold\", \"LeaveOneOut\", \"LeaveOneLabelOut\", etc.\n",
    "inner_cv = KFold(n_splits=5)\n",
    "#inner_cv=StratifiedKFold(n_splits=10)\n",
    "\n",
    "classifier = GridSearchCV(clf, tuned_parameters, cv=inner_cv, scoring='f1_macro')\n",
    "model = classifier.fit(train_features, y_train)\n",
    "scores = classifier.best_score_\n",
    "scores_std = classifier.cv_results_['std_test_score']\n",
    "print('F1-macro of '+classifier.__class__.__name__+' is '+str(scores))\n",
    "print('F1-macro std of '+classifier.__class__.__name__+' is '+ str(scores_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifiers = [\n",
    "    LogisticRegression(C=0.1,solver='liblinear',max_iter=200),\n",
    "    KNeighborsClassifier(9),\n",
    "    SVC( kernel=\"linear\", class_weight=\"balanced\", C=0.1, probability=True),\n",
    "    #NuSVC(kernel=\"rbf\", probability=True),\n",
    "    XGBClassifier(learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27),\n",
    "    DecisionTreeClassifier(criterion = \"gini\", random_state = 100,\n",
    "                               max_depth=3, min_samples_leaf=5),\n",
    "    RandomForestClassifier(n_estimators=500),\n",
    "    AdaBoostClassifier(n_estimators=500),\n",
    "    MultinomialNB(alpha=1.0, fit_prior=True, class_prior=None),\n",
    "    BernoulliNB()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
